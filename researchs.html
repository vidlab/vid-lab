<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Researches</title>
  <link rel="icon" type="image/x-icon" href="assets/images/favicon.png">
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/css/bootstrap.min.css" rel="stylesheet">
  <link
    href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&display=swap"
    rel="stylesheet">
  <link rel="stylesheet" href="assets/css/style.css">
</head>

<body class="all-class-padding">
  <!-- PAGE LOADER: runs until window.load, then disappears -->
  <div id="pageLoader">
    <div class="loader-bars">
      <span></span>
      <span></span>
      <span></span>
      <span></span>
      <span></span>
    </div>
  </div>

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg fixed-top shadow-sm">
    <div class="container">

      <div class="logo-container navbar-brand">
        <div class="logo-img-wrapper">
          <img src="assets/images/favicon.png" alt="Favicon" class="logo-img" style="width: 23px; height: 23px;">
        </div>
        <div class="logo-text-wrapper">
          <a href="index.html" class="logo-link">VIDLab</a>
        </div>
      </div>

      <!-- Bootstrap toggler (hidden on mobile) -->
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
        aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <!-- Custom hamburger menu (shown on mobile) -->
      <button class="custom-hamburger" id="customHamburger">
        <span></span>
        <span></span>
        <span></span>
      </button>

      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ms-auto">
          <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
          <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
          <li class="nav-item"><a class="nav-link active" href="researchs.html">Research</a></li>
          <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
          <li class="nav-item"><a class="nav-link" href="news.html">News</a></li>
          <li class="nav-item"><a class="nav-link" href="gallery.html">Gallery</a></li>
        </ul>
      </div>
    </div>
  </nav>


  <!-- Overlay for mobile menu -->
  <div class="menu-overlay" id="menuOverlay"></div>


  <!-- Header -->
  <section class="py-5 text-center all-header-main">
    <div class="container">
      <h2 class="fw-bold mb-3">Research Projects</h2>
      <p class="lead">Explore our research driving innovation in science and technology frontiers.</p>
    </div>
  </section>

  <!-- Modal -->
  <div class="modal fade" id="researchModal" tabindex="-1" aria-labelledby="researchModalLabel" aria-hidden="true">
    <div class="modal-dialog">
      <div class="modal-content">
        <div class="modal-body">
          <img id="modalResearchImage" src="" class="img-fluid" alt="Full-Sized Image">
        </div>
      </div>
    </div>
  </div>

  <!-- Completed Projects Section -->
  <div class="research-section">
    <div class="container py-4">

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border">
            <div class="row g-0">
              <div class="col-md-5">
                <img src="assets/images/research_projects/DAS-Conv.png" alt="Agricultural Segmentation"
                  class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">Agricultural Image Semantic Segmentation</h3>
                  <p class="research-description">
                    Agricultural image semantic segmentation is a pivotal component of modern agriculture, enabling
                    accurate visual data analysis for improved crop management and resource optimization. This study
                    introduces a segmentation method for precision agriculture that integrates a Dual Atrous Separable
                    Convolution (DAS-Conv) module within a DeepLabV3 framework. The DAS-Conv module balances dilation
                    rates and padding to enhance performance efficiently. A skip connection from the encoder to decoder
                    improves fine-grained spatial feature capture. Tested on the Agriculture-Vision dataset, the model
                    surpasses its baseline and performs comparably to transformer-based SOTA models, while offering over
                    66% better efficiency in the complexity-performance trade-off.
                    <a href="https://www.researchtv.ca/gradflix-lakehead-university-graduate-student-research-1/videos/cling-das-conv-a-deep-learning-module-for-improving-semantic-segmentation-for-precision-agriculture"
                      class="text-primary text-decoration-none">[Research Overview]</a>
                  </p>

                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Precision Agriculture</span>
                    <span class="keyword-tag">Semantic Segmentation</span>
                    <span class="keyword-tag">Deep Learning</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border">
            <div class="row g-0">
              <div class="col-md-5">
                <img src="assets/images/research_projects/fake_news_poster.png" alt="Agricultural Segmentation"
                  class="research-image" class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">NLP-driven Content Classification</h3>
                  <p class="research-description">
                    Fake news is a major issue in today's world, and detecting it is a crucial yet difficult task.
                    Identifying fake news is a high priority for NLP, and the goal of automatic fake news detection is
                    to reduce the time and effort required by individuals to identify and remove misleading news. This
                    study proposes the hybrid model, which is a combination of supervised (SVM, Random Forest, etc.) and
                    unsupervised (K Means clustering) learning models. This study also shows how CNN can be used to
                    improve performance, and the model performs better on bullying vs non-bullying problems as well.
                    <a href="https://ieeexplore.ieee.org/abstract/document/10292460"
                      class="text-primary text-decoration-none">[View Paper]</a>
                  </p>


                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Supervised Learning</span>
                    <span class="keyword-tag">Hybrid Model</span>
                    <span class="keyword-tag">NLP</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border">
            <div class="row g-0">
              <div class="col-md-5">
                <img src="assets/images/research_projects/fake_news_poster.png" alt="Agricultural Segmentation"
                  class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">Improving Pavement Crack Segmentation</h3>
                  <p class="research-description">
                    Image segmentation is vital for numerous applications, including autonomous driving, agriculture,
                    and medical imaging. This study presents a lightweight model for pavement crack segmentation that
                    integrates attention mechanisms and self-gated activation. The model achieves a 1.85% improvement in
                    mean intersection over union (mIoU) and delivers efficient per-sample inference time of 237ms,
                    making it well-suited for real-time use. Extensive experiments on two benchmark datasets validate
                    its performance against recent methods. The model is designed to handle varying lighting conditions
                    and large-scale pavement areas, addressing critical challenges in crack detection while maintaining
                    accuracy and computational efficiency. <a
                      href="https://ieeexplore.ieee.org/abstract/document/10667187"
                      class="text-primary text-decoration-none"> [View Paper]</a>
                  </p>

                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Autonomous Driving</span>
                    <span class="keyword-tag">Segmentation Model</span>
                    <span class="keyword-tag">Neural Networks</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border">
            <div class="row g-0">
              <div class="col-md-5">
                <img
                  src="assets/images/research_projects/enhancement_of_brain_tumor_segmentation_using_multi-modality_learning.png"
                  alt="Agricultural Segmentation" class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">Multi-class Brain Tumor Segmentation</h3>
                  <p class="research-description">
                    A brain tumor: an abnormal growth of tissue, which is found to be unchecked by the normal cell-cycle
                    control mechanism. Early detection of brain tumors is imperative for enhancing patient care,
                    tailoring treatment strategies, and saving lives. Manual segmentation requires a high level of
                    expertise and is time-consuming. This study proposes a graph attention (GAT)-based model by
                    exploiting multichannel (FLAIR, T1CE, T1, and T2) MRI modalities for brain tumor segmentation. <a
                      href="https://ieeexplore.ieee.org/abstract/document/10270859"
                      class="text-primary text-decoration-none"> [View Paper]</a>
                  </p>

                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Medical Imaging</span>
                    <span class="keyword-tag">GAT Model</span>
                    <span class="keyword-tag">Attention Network</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border">
            <div class="row g-0">
              <div class="col-md-5">
                <img src="assets/images/research_projects/video_surveillance_poster.png" alt="Agricultural Segmentation"
                  class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">Video Surveillance Unusual Activity Recognition</h3>
                  <p class="research-description">
                    This research addresses the critical problem of anomaly detection in video surveillance for public
                    safety. It introduces a hybrid feature extraction framework that combines VGG16/ResNet50 with
                    LSTM-based neural networks to improve detection accuracy. The proposed M6 model, utilizing ResNet50
                    and VGG16, achieves superior performance across various datasets (UCF, Avenue, BOSS, Shanghai,
                    Behave) compared to other models. The framework integrates both normal and anomalous videos for
                    training and evaluates performance through detection accuracy, demonstrating a significant
                    improvement in identifying unusual events.
                  </p>

                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Video Surveillance</span>
                    <span class="keyword-tag">LSTM Networks</span>
                    <span class="keyword-tag">Anomaly Detection</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <div class="row justify-content-center">
        <div class="col-lg-10">
          <div class="research-card position-relative border" style="margin-bottom: 0 !important;">
            <div class="row g-0">
              <div class="col-md-5">
                <img src="assets/images/research_projects/bug_report.png" alt="Agricultural Segmentation"
                  class="research-image">
              </div>
              <div class="col-md-7">
                <div class="research-content">
                  <h3 class="research-title text-center">Fast Detection of Duplicate Bug Reports</h3>
                  <p class="research-description">
                    During the development and maintenance of a software, a bug is detected by the bug tracking system
                    and a bug report is generated. Identical problem: There can be already existing bug reports, which
                    were reported to the developer earlier, but the same problem can be reported over and over. It
                    causes waste of development time solving a solved bug. So, it is extremely important to detect the
                    duplicate bug reports. The proposed solution predicts the overwhelming of incoming bug reports as
                    duplicates entries or not using LDA-based clustering and ML-based classification in a time efficient
                    manner.
                    <a href="https://ieeexplore.ieee.org/abstract/document/9283289"
                      class="text-primary text-decoration-none"> [View Paper]</a>
                  </p>

                  <button type="button" class="read-more-btn btn btn-link p-0">Read More</button>

                  <div class="keywords">
                    <span class="keyword-tag">Bug Tracking</span>
                    <span class="keyword-tag">LDA-based Clustering</span>
                    <span class="keyword-tag">ML-based Classification</span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>

      <!-- If you are adding new rsearches, make sure to remove this (style="margin-bottom: 0 !important;")
            from Research Card "Fast Detection of Duplicate Bug Reports". Yes This Code Sucks!
      -->

    </div>
  </div>

  <!-- Footer -->
  <footer class="text-light pt-3 ">
    <div class="container">

      <!-- Desktop/tablet footer: visible from md and up -->
      <div class="row text-center footer_element_height d-none d-md-flex">
        <div class="col-md-4 d-flex flex-column align-items-center justify-content-center">
          <h6 class="fw-bold">Vision Intelligence and Data Lab</h6>
          <p>Advancing intelligent systems through cutting-edge research in computer vision, data analytics, machine
            learning, and AI to address real-world challenges with practical, impactful technological solutions.</p>
        </div>
        <div class="col-md-4 d-flex align-items-center justify-content-center">
          <img src="assets/images/lablogo.png" alt="Logo" class="img-fluid footer-logo">
        </div>
        <div class="col-md-4 d-flex flex-column align-items-center justify-content-center  text-center">
          <h6 class="fw-bold">Address</h6>
          <p>Vision Intelligence and Data Lab<br>
            Lakehead University<br>
            Thunder Bay, Ontario, Canada<br>
            Monday to Friday (8.00AM - 5.00PM)<br>
            <a href="https://www.google.com/maps/search/Lakehead+University,+Thunder+Bay,+Ontario,+Canada/@48.424393,-89.2591852,14z"
              class="text-info text-decoration-none">Location</a>
          </p>
        </div>
      </div>

      <!-- Mobile-only footer: visible below md -->
      <div class="row d-flex d-md-none text-center justify-content-center">
        <div class="col-12 d-flex flex-column align-items-center text-center">
          <h6 class="fw-bold">Vision Intelligence and Data Lab</h6>
          <p>
            Lakehead University<br>
            Thunder Bay, Ontario, Canada<br>
            Monday to Friday (8.00AM - 5.00PM)<br>
            <a href="https://www.google.com/maps/search/Lakehead+University,+Thunder+Bay,+Ontario,+Canada/@48.424393,-89.2591852,14z"
              class="text-info text-decoration-none">Location</a>
          </p>
        </div>
      </div>

      <hr class="border-secondary">
      <!-- Desktop/tablet footer: visible from md and up -->
      <div class="text-center pb-3 d-none d-md-block">
        <small>© 2025 Vision Intelligence and Data Lab. All rights reserved.</small>
      </div>

      <!-- Mobile-only footer: visible below md -->
      <div class="text-center pb-3 d-block d-md-none">
        <small>© 2025 VIDLab. All rights reserved.</small>
      </div>
    </div>
  </footer>

  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.6/dist/js/bootstrap.bundle.min.js"></script>
  <script src="assets/js/script.js"></script>
</body>

</html>